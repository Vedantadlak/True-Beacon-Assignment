{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_parquet('data.parquet')\n",
        "mask = (data.index.time >= pd.Timestamp('09:15').time()) & (data.index.time <= pd.Timestamp('15:30').time())\n",
        "data = data[mask]\n",
        "\n",
        "data = data.ffill()\n",
        "\n",
        "data['Spread'] = data['nifty'] - data['banknifty']\n",
        "\n",
        "lookback_period = 20\n",
        "\n",
        "data['Rolling_Mean'] = data['Spread'].rolling(lookback_period).mean()\n",
        "data['Rolling_Std'] = data['Spread'].rolling(lookback_period).std()\n",
        "\n",
        "data['Z_Score'] = (data['Spread'] - data['Rolling_Mean']) / data['Rolling_Std']\n",
        "\n",
        "entry_threshold = -2\n",
        "exit_threshold = -1\n",
        "\n",
        "data['Signal'] = 0\n",
        "data['Position'] = 0\n",
        "\n",
        "data.loc[data['Z_Score'] < entry_threshold, 'Signal'] = 1\n",
        "data.loc[data['Z_Score'] > exit_threshold, 'Signal'] = -1\n",
        "\n",
        "data['Position'] = data['Signal'].ffill().fillna(0)\n",
        "\n",
        "data['P/L'] = data['Position'].shift(1) * data['Spread'].diff()\n",
        "\n",
        "absolute_pl = data['P/L'].sum()\n",
        "sharpe_ratio = data['P/L'].mean() / data['P/L'].std() * np.sqrt(252)\n",
        "drawdown = (data['P/L'].cumsum() / data['P/L'].cumsum().cummax()).min()\n",
        "\n",
        "print(f\"Absolute P/L: {absolute_pl:.2f}\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
        "print(f\"Drawdown: {drawdown:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_GOt9WeJAEn",
        "outputId": "acfd1bdb-4585-49c1-e4c0-a75e30083f1c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute P/L: 30.83\n",
            "Sharpe Ratio: 0.84\n",
            "Drawdown: -inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "data = pd.read_parquet('data.parquet')\n",
        "\n",
        "mask = (data.index.time >= pd.Timestamp('09:15').time()) & (data.index.time <= pd.Timestamp('15:30').time())\n",
        "data = data[mask]\n",
        "\n",
        "data = data.ffill()\n",
        "\n",
        "data['Spread'] = data['nifty'] - data['banknifty']\n",
        "\n",
        "train_data = data['Spread'].iloc[:int(0.8 * len(data))]\n",
        "test_data = data['Spread'].iloc[int(0.8 * len(data)):]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_data_scaled = scaler.fit_transform(train_data.values.reshape(-1, 1))\n",
        "test_data_scaled = scaler.transform(test_data.values.reshape(-1, 1))\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "lookback = 60\n",
        "\n",
        "for i in range(lookback, len(train_data_scaled)):\n",
        "    X_train.append(train_data_scaled[i - lookback:i, 0])\n",
        "    y_train.append(train_data_scaled[i, 0])\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(LSTM(units=32))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "X_test = []\n",
        "for i in range(lookback, len(test_data_scaled)):\n",
        "    X_test.append(test_data_scaled[i - lookback:i, 0])\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "predictions_scaled = model.predict(X_test)\n",
        "predictions = scaler.inverse_transform(predictions_scaled)\n",
        "\n",
        "test_data = test_data.to_frame().reset_index()\n",
        "test_data['Predictions'] = predictions.ravel()\n",
        "\n",
        "entry_threshold = 0.5\n",
        "exit_threshold = -0.5\n",
        "\n",
        "test_data['Signal'] = 0\n",
        "test_data['Position'] = 0\n",
        "\n",
        "test_data.loc[test_data['Predictions'] > entry_threshold, 'Signal'] = 1\n",
        "test_data.loc[test_data['Predictions'] < exit_threshold, 'Signal'] = -1\n",
        "\n",
        "test_data['Position'] = test_data['Signal'].ffill().fillna(0)\n",
        "\n",
        "test_data['P/L'] = test_data['Position'].shift(1) * test_data['Spread'].diff()\n",
        "\n",
        "absolute_pl = test_data['P/L'].sum()\n",
        "sharpe_ratio = test_data['P/L'].mean() / test_data['P/L'].std() * np.sqrt(252)\n",
        "drawdown = (test_data['P/L'].cumsum() / test_data['P/L'].cumsum().cummax()).min()\n",
        "\n",
        "print(f\"Absolute P/L: {absolute_pl:.2f}\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
        "print(f\"Drawdown: {drawdown:.2f}\")"
      ],
      "metadata": {
        "id": "hLSXMComLx_E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}